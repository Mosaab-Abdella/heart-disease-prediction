{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPJv5GnW+ltlk1Mf3fGrWGM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4qAT7SWxcTCw","executionInfo":{"status":"ok","timestamp":1758293279118,"user_tz":-180,"elapsed":24579,"user":{"displayName":"Mosab Abdella","userId":"16043805174010566712"}},"outputId":"fe55e3af-5561-42d9-e226-3cccbe60cc24"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train/Test sizes: (242, 7) (61, 7)\n","\n","Best Logistic Regression Params: {'clf__C': 10, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}\n","\n","=== Logistic Regression (Tuned) ===\n","Accuracy: 0.8688524590163934\n","Precision: 0.8125\n","Recall: 0.9285714285714286\n","F1: 0.8666666666666667\n","ROC-AUC: 0.9383116883116882\n","\n","Best Decision Tree Params: {'clf__max_depth': 3, 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 2}\n","\n","=== Decision Tree (Tuned) ===\n","Accuracy: 0.8688524590163934\n","Precision: 0.8571428571428571\n","Recall: 0.8571428571428571\n","F1: 0.8571428571428571\n","ROC-AUC: 0.8701298701298701\n","\n","Best Random Forest Params: {'clf__n_estimators': 100, 'clf__min_samples_split': 5, 'clf__min_samples_leaf': 2, 'clf__max_depth': 10}\n","\n","=== Random Forest (Tuned) ===\n","Accuracy: 0.9016393442622951\n","Precision: 0.8928571428571429\n","Recall: 0.8928571428571429\n","F1: 0.8928571428571429\n","ROC-AUC: 0.9556277056277056\n","\n","Best SVC Params: {'clf__C': 1, 'clf__gamma': 'scale', 'clf__kernel': 'rbf'}\n","\n","=== SVC (Tuned) ===\n","Accuracy: 0.8688524590163934\n","Precision: 0.8333333333333334\n","Recall: 0.8928571428571429\n","F1: 0.8620689655172413\n","ROC-AUC: 0.935064935064935\n","\n","✅ Hyperparameter tuning complete! Best models saved as .pkl files.\n"]}],"source":["# 1. Imports\n","# =========================\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","import joblib\n","\n","# =========================\n","# 2. Load Data\n","# =========================\n","data = pd.read_csv(\"heart_disease_selected.csv\")\n","target_col = \"num\"\n","\n","X = data.drop(columns=[target_col])\n","y = data[target_col].apply(lambda x: 1 if x > 0 else 0)\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42, stratify=y\n",")\n","\n","print(\"Train/Test sizes:\", X_train.shape, X_test.shape)\n","\n","# =========================\n","# 3. Helper Function\n","# =========================\n","def evaluate(name, model, X_test, y_test):\n","    y_pred = model.predict(X_test)\n","    if hasattr(model, \"predict_proba\"):\n","        y_proba = model.predict_proba(X_test)[:, 1]\n","        auc = roc_auc_score(y_test, y_proba)\n","    else:\n","        auc = None\n","\n","    print(f\"\\n=== {name} ===\")\n","    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","    print(\"Precision:\", precision_score(y_test, y_pred))\n","    print(\"Recall:\", recall_score(y_test, y_pred))\n","    print(\"F1:\", f1_score(y_test, y_pred))\n","    print(\"ROC-AUC:\", auc)\n","\n","# =========================\n","# 4. Logistic Regression Tuning\n","# =========================\n","lr_pipeline = Pipeline([\n","    (\"scaler\", StandardScaler()),\n","    (\"clf\", LogisticRegression(max_iter=2000))\n","])\n","\n","lr_param_grid = {\n","    \"clf__C\": [0.01, 0.1, 1, 10, 100],\n","    \"clf__penalty\": [\"l2\"],\n","    \"clf__solver\": [\"lbfgs\", \"saga\"]\n","}\n","\n","lr_gs = GridSearchCV(lr_pipeline, lr_param_grid, cv=5, scoring=\"roc_auc\", n_jobs=-1)\n","lr_gs.fit(X_train, y_train)\n","\n","print(\"\\nBest Logistic Regression Params:\", lr_gs.best_params_)\n","evaluate(\"Logistic Regression (Tuned)\", lr_gs.best_estimator_, X_test, y_test)\n","\n","joblib.dump(lr_gs.best_estimator_, \"model_logistic_regression_tuned.pkl\")\n","\n","# =========================\n","# 5. Decision Tree Tuning\n","# =========================\n","dt_pipeline = Pipeline([\n","    (\"scaler\", StandardScaler()),\n","    (\"clf\", DecisionTreeClassifier(random_state=42))\n","])\n","\n","dt_param_grid = {\n","    \"clf__max_depth\": [None, 3, 5, 10],\n","    \"clf__min_samples_split\": [2, 5, 10],\n","    \"clf__min_samples_leaf\": [1, 2, 4]\n","}\n","\n","dt_gs = GridSearchCV(dt_pipeline, dt_param_grid, cv=5, scoring=\"roc_auc\", n_jobs=-1)\n","dt_gs.fit(X_train, y_train)\n","\n","print(\"\\nBest Decision Tree Params:\", dt_gs.best_params_)\n","evaluate(\"Decision Tree (Tuned)\", dt_gs.best_estimator_, X_test, y_test)\n","\n","joblib.dump(dt_gs.best_estimator_, \"model_decision_tree_tuned.pkl\")\n","\n","# =========================\n","# 6. Random Forest Tuning\n","# =========================\n","rf_pipeline = Pipeline([\n","    (\"scaler\", StandardScaler()),\n","    (\"clf\", RandomForestClassifier(random_state=42))\n","])\n","\n","rf_param_grid = {\n","    \"clf__n_estimators\": [50, 100, 200],\n","    \"clf__max_depth\": [None, 5, 10, 20],\n","    \"clf__min_samples_split\": [2, 5, 10],\n","    \"clf__min_samples_leaf\": [1, 2, 4]\n","}\n","\n","rf_rs = RandomizedSearchCV(rf_pipeline, rf_param_grid, n_iter=10,\n","                           cv=5, scoring=\"roc_auc\", n_jobs=-1, random_state=42)\n","rf_rs.fit(X_train, y_train)\n","\n","print(\"\\nBest Random Forest Params:\", rf_rs.best_params_)\n","evaluate(\"Random Forest (Tuned)\", rf_rs.best_estimator_, X_test, y_test)\n","\n","joblib.dump(rf_rs.best_estimator_, \"model_random_forest_tuned.pkl\")\n","\n","# =========================\n","# 7. SVM Tuning\n","# =========================\n","svc_pipeline = Pipeline([\n","    (\"scaler\", StandardScaler()),\n","    (\"clf\", SVC(probability=True, random_state=42))\n","])\n","\n","svc_param_grid = {\n","    \"clf__C\": [0.1, 1, 10, 100],\n","    \"clf__gamma\": [\"scale\", \"auto\"],\n","    \"clf__kernel\": [\"rbf\", \"linear\"]\n","}\n","\n","svc_gs = GridSearchCV(svc_pipeline, svc_param_grid, cv=5, scoring=\"roc_auc\", n_jobs=-1)\n","svc_gs.fit(X_train, y_train)\n","\n","print(\"\\nBest SVC Params:\", svc_gs.best_params_)\n","evaluate(\"SVC (Tuned)\", svc_gs.best_estimator_, X_test, y_test)\n","\n","joblib.dump(svc_gs.best_estimator_, \"model_svc_tuned.pkl\")\n","\n","print(\"\\n✅ Hyperparameter tuning complete! Best models saved as .pkl files.\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"P0IX7RNLceCH"},"execution_count":null,"outputs":[]}]}